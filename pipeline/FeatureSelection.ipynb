{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group 04 | Feature Selection\n",
    "\n",
    "-------------------------\n",
    "Amber Curran (akc6be)\n",
    "\n",
    "Manpreet Dhindsa (mkd8bb)\n",
    "\n",
    "Quinton Mays (rub9ez)\n",
    "\n",
    "---------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin feature selection, a spark session is created and the imported dataframe is read from the parquet file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "        .appName(\"group04VarSel2\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(\"/project/ds5559/fa21-group04/data/df.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we import the modules necessary for creating pyspark pipelines and for importing the data dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.ml.feature import *\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml import Pipeline  \n",
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We specify that the model features are all columns that are not `hospital_death`, which is our response variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_features = [col for col in df.columns if col not in ['hospital_death']] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data dictionary is read into a `pandas` dataframe and then zipped to a dictionary containing the feature names and data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "schemadf = pd.read_csv('/project/ds5559/fa21-group04/data/WiDS_Datathon_2020_Dictionary.csv')\n",
    "schemadf = schemadf[schemadf['Variable Name'] != 'icu_admit_type']\n",
    "var_types = dict(zip(schemadf['Variable Name'], schemadf['Data Type']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then split the features by type into four lists: \n",
    "\n",
    "<b>Categorical Feature Types </b>\n",
    "1. Integer\n",
    "2. Binary\n",
    "3. String\n",
    "\n",
    "<b>Continuous Feature Types </b>\n",
    "\n",
    "4. Float\n",
    "\n",
    "The engineered features (average features created in DATA EXPLORATION AND CLEANING notebook), are excluded from the list comprehension as they are not included in the data dictionary. They are then concatenated onto float list, as they are all floating point values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_vars = ['bmi'] # any variables that we want to give special treatment (bucketize, etc)\n",
    "engineered_vars = [col for col in model_features if col not in list(var_types.keys())]\n",
    "exclude_vars = special_vars + engineered_vars\n",
    "orig_vars = [col for col in model_features if col in list(var_types.keys())]\n",
    "model_int_vars = [col for col in orig_vars if var_types[col] == 'integer' and col not in exclude_vars]\n",
    "model_float_vars = [col for col in orig_vars if var_types[col] == 'numeric' and col not in exclude_vars] + engineered_vars + ['bmi']\n",
    "model_binary_vars = [col for col in orig_vars if var_types[col] == 'binary' and col not in exclude_vars]\n",
    "model_string_vars = [col for col in orig_vars if var_types[col] == 'string' and col not in exclude_vars]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The possible model features are shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible Model Integer Features : ['hospital_id', 'icu_id']\n"
     ]
    }
   ],
   "source": [
    "print('Possible Model Integer Features : {}'.format(model_int_vars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible Model Float Features : ['age', 'height', 'pre_icu_los_days', 'weight', 'apache_4a_hospital_death_prob', 'apache_4a_icu_death_prob', 'avgmaxtod1_diasbp_min', 'avgmaxtod1_heartrate_min', 'avgmaxtod1_mbp_min', 'avgmaxtod1_resprate_min', 'avgmaxtod1_spo2_min', 'avgmaxtod1_sysbp_min', 'avgmaxtod1_temp_min', 'avgmaxtoh1_diasbp_min', 'avgmaxtoh1_heartrate_min', 'avgmaxtoh1_mbp_min', 'avgmaxtoh1_resprate_min', 'avgmaxtoh1_spo2_min', 'avgmaxtoh1_sysbp_min', 'avgmaxtoh1_temp_min', 'avgmaxtod1_bun_min', 'avgmaxtod1_calcium_min', 'avgmaxtod1_creatinine_min', 'avgmaxtod1_glucose_min', 'avgmaxtod1_hco3_min', 'avgmaxtod1_hemaglobin_min', 'avgmaxtod1_hematocrit_min', 'avgmaxtod1_platelets_min', 'avgmaxtod1_potassium_min', 'avgmaxtod1_sodium_min', 'avgmaxtod1_wbc_min', 'bmi']\n"
     ]
    }
   ],
   "source": [
    "print('Possible Model Float Features : {}'.format(model_float_vars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible Model Binary Features : ['elective_surgery', 'readmission_status', 'aids', 'cirrhosis', 'diabetes_mellitus', 'hepatic_failure', 'immunosuppression', 'leukemia', 'lymphoma', 'solid_tumor_with_metastasis']\n"
     ]
    }
   ],
   "source": [
    "print('Possible Model Binary Features : {}'.format(model_binary_vars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible Model String Features : ['ethnicity', 'gender', 'hospital_admit_source', 'icu_admit_source', 'icu_stay_type', 'icu_type', 'apache_3j_bodysystem', 'apache_2_bodysystem']\n"
     ]
    }
   ],
   "source": [
    "print('Possible Model String Features : {}'.format(model_string_vars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine the features to use in our model, two `UnivariateFeatureSelector` pipelines are constructed; one for categorical features and one for continuous features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, as all of the integer variables in our model are categorical variables, they are vectorized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_var_vectorizer = VectorAssembler(inputCols=model_int_vars, outputCol='intFeatures', handleInvalid='skip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likewise, binary variables are also vectorized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_var_vectorizer = VectorAssembler(inputCols=model_binary_vars, \n",
    "                                        outputCol='binaryFeatures',\n",
    "                                        handleInvalid='skip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "String variables are passed to a `StringIndexer` object to convert them to integers and then to a `VectorAssembler` to process them into a feature vector for possible selection by the `UnivariateFeatureSelector`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_string_vars = ['{}_indexed'.format(var) for var in model_string_vars]\n",
    "string_var_indexer = StringIndexer(inputCols=model_string_vars,\n",
    "                                   outputCols=indexed_string_vars,\n",
    "                                   handleInvalid='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_var_vectorizer = VectorAssembler(inputCols=string_var_indexer.getOutputCols(),\n",
    "                                        outputCol='StringFeatures',\n",
    "                                        handleInvalid='skip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, categorical features are combined into one `VectorAssembler` and passed to a `UnivariateFeatureSelector` object in the pipeline to choose which variables are most useful for determining the outcome, `hospital_death`. As these features are categorical, and the response is categorical, the `UnivariateFeatureSelector` uses a Chi-Squared test for determining which categorical variables to include in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feature_vectorizer = VectorAssembler(inputCols=[string_var_vectorizer.getOutputCol(),\n",
    "                                                    int_var_vectorizer.getOutputCol(),\n",
    "                                                    string_var_vectorizer.getOutputCol()],\n",
    "                                        outputCol='catFeatures',\n",
    "                                        handleInvalid='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_selector = UnivariateFeatureSelector(featuresCol=cat_feature_vectorizer.getOutputCol(),\n",
    "                                         labelCol='hospital_death',\n",
    "                                         outputCol='selectedCatFeatures').setFeatureType('categorical').setLabelType('categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A piepline is then constructed and fit to the data using the created objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_pipeline = Pipeline(stages=[\n",
    "    int_var_vectorizer,\n",
    "    binary_var_vectorizer,\n",
    "    string_var_indexer,\n",
    "    string_var_vectorizer,\n",
    "    cat_feature_vectorizer,\n",
    "    cat_selector\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_model = cat_pipeline.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cat_model.transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the features that the `UnivariateFeatureSelector` chose are shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "catfeat = cat_model.stages[0].getInputCols() + cat_model.stages[1].getInputCols() + cat_model.stages[3].getInputCols() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cat_feats = [catfeat[i] for i in cat_model.stages[5].selectedFeatures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['elective_surgery',\n",
       " 'readmission_status',\n",
       " 'cirrhosis',\n",
       " 'diabetes_mellitus',\n",
       " 'hepatic_failure',\n",
       " 'immunosuppression',\n",
       " 'leukemia',\n",
       " 'ethnicity_indexed',\n",
       " 'gender_indexed',\n",
       " 'icu_admit_source_indexed',\n",
       " 'icu_stay_type_indexed',\n",
       " 'icu_type_indexed',\n",
       " 'aids',\n",
       " 'hospital_admit_source_indexed',\n",
       " 'icu_id',\n",
       " 'solid_tumor_with_metastasis',\n",
       " 'hospital_id',\n",
       " 'lymphoma']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_cat_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The string features, which must be one hot encoded for any model, are separated from the other categorical features for further processing by a `OneHotEncoder`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_string_feats = [feat for feat in indexed_string_vars if feat in selected_cat_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ethnicity_indexed',\n",
       " 'gender_indexed',\n",
       " 'hospital_admit_source_indexed',\n",
       " 'icu_admit_source_indexed',\n",
       " 'icu_stay_type_indexed',\n",
       " 'icu_type_indexed']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_string_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `OneHotEncoder` object is then created for the final pipeline. It one hot encodes the features that were selected in the previous pipeline for use in future models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_string_vars = ['{}_ohe'.format(var) for var in selected_string_feats]\n",
    "string_var_ohe = OneHotEncoder(inputCols=selected_string_feats,outputCols=ohe_string_vars)\n",
    "\n",
    "string_var_vectorizer = VectorAssembler(inputCols=string_var_ohe.getOutputCols(),\n",
    "                                        outputCol='SelectedStringFeatures',\n",
    "                                        handleInvalid='skip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The oter variables are passed to their own `VectorAssembler` and then all features are combined into a final feature vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_var_vectorizer = VectorAssembler(inputCols=[col for col in selected_cat_feats if col not in selected_string_feats],\n",
    "                                       outputCol='oheCatFeatures',\n",
    "                                       handleInvalid='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cat_vectorizer = VectorAssembler(inputCols=[string_var_vectorizer.getOutputCol(),\n",
    "                                                  other_var_vectorizer.getOutputCol()],\n",
    "                                       outputCol='FinalCatFeatures',\n",
    "                                       handleInvalid='skip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pipeline is then constructed that is identical to the first pipeline with the exception of the inclusion of the `OneHotEncoder` for the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cat_pipeline = Pipeline(stages=[\n",
    "    string_var_ohe,\n",
    "    string_var_vectorizer,\n",
    "    other_var_vectorizer,\n",
    "    final_cat_vectorizer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cat_model = final_cat_pipeline.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = final_cat_model.transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determining the continuous features to use in the model was also accomplished using a `UnivariateFeatureSelector` object. In addition, these features are also imputed to the feature mean to remove any `Nan` from the dataset. In the case of a continuous predictor and a categorical response, the `UnivariateFeatureSelector` uses an ANOVA F-Test to determine which variables to include in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_float_vars = ['{}_imputed'.format(var) for var in model_float_vars]\n",
    "float_imputer = Imputer(inputCols=model_float_vars, outputCols=imputed_float_vars)\n",
    "\n",
    "float_var_vectorizer = VectorAssembler(inputCols=float_imputer.getOutputCols(), outputCol='floatFeatures', handleInvalid='skip')\n",
    "\n",
    "float_MaxAbs_Scaler = MaxAbsScaler(inputCol=float_var_vectorizer.getOutputCol(),\n",
    "                                   outputCol='scaledFloatFeatures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_selector = UnivariateFeatureSelector(featuresCol=float_MaxAbs_Scaler.getOutputCol(),\n",
    "                                          labelCol='hospital_death',\n",
    "                                          outputCol='selectedContFeatures').setFeatureType('continuous').setLabelType('categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_pipeline = Pipeline(stages=[\n",
    "    float_imputer,\n",
    "    float_var_vectorizer,\n",
    "    float_MaxAbs_Scaler,\n",
    "    cont_selector\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The constructured piepline is then fit to the data and used to transform the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_model = cont_pipeline.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cont_model.transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chosen continuous features are shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age_imputed',\n",
       " 'pre_icu_los_days_imputed',\n",
       " 'weight_imputed',\n",
       " 'apache_4a_hospital_death_prob_imputed',\n",
       " 'apache_4a_icu_death_prob_imputed',\n",
       " 'avgmaxtod1_diasbp_min_imputed',\n",
       " 'avgmaxtod1_heartrate_min_imputed',\n",
       " 'avgmaxtod1_mbp_min_imputed',\n",
       " 'avgmaxtod1_resprate_min_imputed',\n",
       " 'avgmaxtod1_spo2_min_imputed',\n",
       " 'avgmaxtod1_sysbp_min_imputed',\n",
       " 'avgmaxtod1_temp_min_imputed',\n",
       " 'avgmaxtoh1_diasbp_min_imputed',\n",
       " 'avgmaxtoh1_heartrate_min_imputed',\n",
       " 'avgmaxtoh1_mbp_min_imputed',\n",
       " 'avgmaxtoh1_resprate_min_imputed',\n",
       " 'avgmaxtoh1_spo2_min_imputed',\n",
       " 'avgmaxtoh1_sysbp_min_imputed',\n",
       " 'avgmaxtoh1_temp_min_imputed',\n",
       " 'avgmaxtod1_bun_min_imputed',\n",
       " 'avgmaxtod1_calcium_min_imputed',\n",
       " 'avgmaxtod1_creatinine_min_imputed',\n",
       " 'avgmaxtod1_glucose_min_imputed',\n",
       " 'avgmaxtod1_hco3_min_imputed',\n",
       " 'avgmaxtod1_hemaglobin_min_imputed',\n",
       " 'avgmaxtod1_hematocrit_min_imputed',\n",
       " 'avgmaxtod1_platelets_min_imputed',\n",
       " 'avgmaxtod1_potassium_min_imputed',\n",
       " 'avgmaxtod1_wbc_min_imputed',\n",
       " 'bmi_imputed',\n",
       " 'height_imputed',\n",
       " 'avgmaxtod1_sodium_min_imputed']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[cont_model.stages[1].getInputCols()[i] for i in cont_model.stages[3].selectedFeatures]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transformed dataframe, inlcuding the columns `CatFeatures` and `selectedContFeatures` is exported for use in the various models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.mode(\"overwrite\").parquet(\"/project/ds5559/fa21-group04/data/processed_df.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS 5110 Spark 3.1",
   "language": "python",
   "name": "ds5110_spark3.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
